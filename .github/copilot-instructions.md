# AI Coding Agent Instructions - KI-Mail-Helper

## Project Overview
KI-Mail-Helper is a self-hosted, zero-knowledge encrypted email organizer with AI-powered prioritization. The entire codebase was generated by AI agents (GitHub Copilot) - no manual code has been written. Current version: 1.3.1 (Production-ready, single-user deployment).

**Core Architecture:**
- **Zero-Knowledge Encryption**: AES-256-GCM with DEK/KEK pattern - server never sees plaintext data
- **3×3 Priority Matrix**: Urgency × Importance scoring with color-coded dashboard
- **Multi-Provider AI**: Supports Ollama (local), OpenAI, Anthropic, Mistral with dynamic model discovery
- **Online Learning**: SGD classifiers learn from user corrections (dringlichkeit/wichtigkeit/spam/kategorie)
- **Email Anonymization**: spaCy NER-based PII removal (DSGVO-compliant) before cloud AI transmission

## Critical Security Architecture

### Master Key & Encryption Flow
**NEVER store master_key in browser cookies or client-side storage.**

- Master key derived from user password via PBKDF2 (600,000 iterations)
- Stored ONLY in server-side Flask sessions ([.flask_sessions/](../.flask_sessions/), gitignored)
- All sensitive data encrypted: email content, IMAP/SMTP credentials, AI results
- Encryption: AES-256-GCM with separate 16-byte salt + 12-byte IV (format: `salt:iv:ciphertext:tag`)
- See [src/08_encryption.py](../src/08_encryption.py) for EncryptionManager implementation

**When adding CLI/background jobs:**
- Master key must be passed explicitly as function parameter
- Example: [src/12_processing.py](../src/12_processing.py#L50) `process_pending_raw_emails(master_key=...)`
- Use Flask context detection: `if flask.has_request_context(): key = session.get('master_key')`

### Security Best Practices
- Use `logger.info(f"User (ID: {user.id})")` - NEVER log usernames, emails, or sensitive data
- All database fields with sensitive data must have `encrypted_*` counterparts
- Templates must decrypt data server-side before rendering (see [src/01_web_app.py](../src/01_web_app.py) `/settings` route)
- Rate limiting: 5 requests/min for login/2FA via Flask-Limiter
- Account lockout: 5 failed attempts → 15min ban

## Database Models & Migrations

**Core Models** ([src/02_models.py](../src/02_models.py)):
- `User`: Master account with 2FA, password_hash, encrypted_master_key
- `MailAccount`: IMAP/SMTP/OAuth credentials (all encrypted), per-account AI toggles
- `RawEmail`: Encrypted raw email data (from IMAP fetch)
- `ProcessedEmail`: Encrypted AI analysis results, embeddings, user corrections
- `EmailTag`: User tags with learned_embedding (aggregated from assigned emails)
- `AutoRule`: Email automation rules (14 condition types, 6 action types)
- `TrustedSender`: Account-based whitelist with urgency_boost override

**Migration Pattern** (Alembic):
```bash
# 1. Generate migration
alembic revision -m "description"

# 2. Edit migrations/versions/xxx_description.py
# - Add columns with nullable=True for existing data
# - Use batch operations for SQLite compatibility

# 3. Test migration
alembic upgrade head
alembic downgrade -1  # verify rollback
```

**Key constraints:**
- SQLite: Use batch operations for ALTER TABLE (see [migrations/versions/](../migrations/versions/))
- Encrypted fields: Always add both `field` and `encrypted_field` columns
- Indexes: Add for foreign keys and frequently filtered columns

## AI Integration Patterns

### Multi-Provider Architecture
**Dynamic Provider Selection** ([src/03_ai_client.py](../src/03_ai_client.py)):
- `build_client(provider, model)` factory pattern returns provider-specific clients
- Each client implements: `analyze_email()`, `generate_embedding()`, `list_models()`
- Available providers detected via API key presence in environment

**Model Discovery** ([src/04_model_discovery.py](../src/04_model_discovery.py)):
- `/api/models/<provider>` endpoint caches model lists (30s server-side)
- Ollama: `GET /api/tags`, OpenAI: `openai.models.list()`, etc.
- Dropdown updates dynamically based on user's API key configuration

### AI Analysis Modes (per MailAccount)
**3 Independent Toggles** ([src/06_mail_fetcher.py](../src/06_mail_fetcher.py)):
1. `enable_ai_analysis_on_fetch`: Full LLM analysis (dringlichkeit/wichtigkeit/kategorie/summary/tags)
2. `enable_urgency_booster`: Fast spaCy entity-based analysis for trusted senders (100-300ms)
3. `anonymize_with_spacy`: PII removal before cloud AI (3 levels: Regex/Light/Full via [src/04_sanitizer.py](../src/04_sanitizer.py))

**Hierarchy:**
- `spacy_booster`: UrgencyBooster on original data (local, no LLM cost)
- `llm_anon`: LLM on anonymized data (DSGVO-compliant for cloud AI)
- `llm_original`: LLM on original data (best quality, Ollama only)
- `none`: Embeddings only, no auto-rating (manual tagging → ML learning)

**Confidence Tracking:**
- `ai_confidence`: Initial analysis quality (0.65-0.9 for hybrid booster based on SGD corrections)
- `optimize_confidence`: Second-pass with better model (NULL for models without native confidence)
- NEVER use fake confidence defaults - use NULL if provider doesn't support it

## Web Application Structure

**Monolithic Flask App** ([src/01_web_app.py](../src/01_web_app.py), 9403 lines):
- All routes in single file with numbered module imports (`00_main.py`, `02_models.py`, etc.)
- Key routes: `/dashboard`, `/list`, `/threads`, `/email/<id>`, `/tags`, `/whitelist`, `/settings`
- CSRF protection via Flask-WTF (enabled globally)
- Server-side sessions via Flask-Session (filesystem-based in [.flask_sessions/](../.flask_sessions/))

**Template Pattern** ([templates/](../templates/)):
- Base template with sidebar navigation
- Decrypt all data server-side before passing to templates
- Use Bootstrap 5 for styling, modals for actions

**Authentication:**
- Login → Password check → 2FA verification (if enabled) → Master key stored in session
- Logout → Master key deleted from session → All encrypted data inaccessible
- No API tokens - web UI only for single-user deployment

## Email Processing Pipeline

### Fetch Flow ([src/06_mail_fetcher.py](../src/06_mail_fetcher.py)):
1. IMAP connect with per-account encryption settings (SSL/STARTTLS/NONE)
2. Apply fetch filters: folder whitelist/blacklist, SINCE date, UNSEEN-only, per-folder limit
3. Check UIDVALIDITY (RFC 3501) - reset UID tracking if changed
4. Fetch UIDs in ranges, save to RawEmail (encrypted)
5. Process: AI analysis (if enabled) → Save to ProcessedEmail → Commit

### Processing Pipeline ([src/12_processing.py](../src/12_processing.py)):
1. Decrypt email content with master_key
2. **Hybrid Analysis** (if AI enabled):
   - Check TrustedSender → Apply UrgencyBooster (spaCy entity detection)
   - Non-trusted → Full LLM analysis (anonymized if configured)
3. Generate embedding (always, even if AI disabled)
4. Calculate score via [src/05_scoring.py](../src/05_scoring.py): `score = dringlichkeit*2 + wichtigkeit`
5. Apply AutoRules (14 condition types: sender/subject/body/regex/tags/ai_suggested_tag)
6. Encrypt results → Save to ProcessedEmail

### Thread Management ([src/thread_service.py](../src/thread_service.py)):
- Thread ID: `SHA256(normalized_subject + sorted_participants)`
- Normalization: Remove "Re:", "Fwd:", whitespace, lowercase
- Thread view groups emails chronologically (oldest → newest)

## Machine Learning System

**Online Learning** ([src/train_classifier.py](../src/train_classifier.py)):
- 4 SGD classifiers: `dringlichkeit`, `wichtigkeit`, `spam`, `kategorie`
- Feature extraction: Ollama embeddings (all-minilm:22m, 384 dimensions)
- Training trigger: User corrects AI prediction → `partial_fit()` on single sample
- Model persistence: Joblib serialization to [src/classifiers/](../src/classifiers/)

**When adding user correction endpoints:**
1. Save correction to `user_override_*` columns in ProcessedEmail
2. Call `OnlineLearner.update_from_correction(email_id, correction_type, new_value)`
3. Classifier learns immediately (no batch retraining needed)

**Tag Learning** ([src/semantic_search.py](../src/semantic_search.py)):
- `EmailTag.learned_embedding`: Averaged embedding from all assigned emails
- Priority: `learned_embedding` > `description` embedding > `name` embedding
- Auto-assignment: ≥80% cosine similarity (configurable)
- Negative feedback: `TagNegativeExample` table penalizes rejected suggestions (0-20% score reduction)

## Development Workflows

### Local Development
```bash
# 1. Setup virtual environment (ALWAYS use venv)
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Install spaCy German model (for anonymization)
python -m spacy download de_core_news_sm

# 3. Configure .env (copy from .env.example)
# Generate FLASK_SECRET_KEY: python3 -c "import secrets; print(secrets.token_hex(32))"

# 4. Initialize database
python3 -m src.00_main --init-db
python3 -m src.00_main --register  # Create first user

# 5. Run web server
python3 -m src.00_main --web
# Access: http://localhost:5000
```

### Testing
```bash
# Run specific test
pytest tests/test_ai_client.py -v

# Run with coverage
pytest --cov=src --cov-report=html tests/

# Integration tests require Ollama running
docker run -d -p 11434:11434 ollama/ollama
```

**Key test files:**
- [tests/test_scoring.py](../tests/test_scoring.py): Priority matrix calculations
- [tests/test_content_sanitizer.py](../tests/test_content_sanitizer.py): PII removal with spaCy
- [tests/test_phase_y2.py](../tests/test_phase_y2.py): ML classifier updates
- [tests/test_whitelist_security.py](../tests/test_whitelist_security.py): Trusted sender isolation

### CLI Usage
```bash
# Fetch emails (requires master key parameter)
python3 -m src.00_main --fetch --user-id 1 --master-key "base64_key"

# Train classifiers (batch mode)
python3 scripts/train_classifier.py --user-id 1

# Check accounts
python3 scripts/list_accounts.py
```

## Common Patterns & Conventions

### Error Handling
- Use `logger.error()` for exceptions, `logger.warning()` for recoverable issues
- Return JSON responses from API endpoints: `{"error": "message"}` with appropriate HTTP status
- Flash messages for user-facing errors: `flash("Message", "danger")`

### Naming Conventions
- Database models: PascalCase (`ProcessedEmail`, `MailAccount`)
- Enums: PascalCase with UPPER values (`EmailColor.RED`, `AIProvider.OLLAMA`)
- Functions: snake_case (`calculate_score`, `process_pending_raw_emails`)
- Routes: kebab-case URLs (`/mail-fetch-config`, `/tag-suggestions`)

### File Organization
- Numbered modules indicate dependency order: `00_main.py` → `01_web_app.py` → `02_models.py`
- Service modules in [src/services/](../src/services/) for complex business logic
- Scripts in [scripts/](../scripts/) for maintenance tasks (database checks, backups, CLI tools)

## Important Constraints

1. **SQLite Limitations**: No concurrent writes - use WAL mode (enabled in [src/02_models.py](../src/02_models.py))
2. **Python 3.12+**: Use `datetime.now(UTC)` instead of deprecated `datetime.utcnow()`
3. **No Frontend Framework**: Pure Jinja2 templates, Bootstrap 5 CSS, vanilla JavaScript
4. **Single-User Focus**: No multi-tenancy, user isolation via foreign keys only
5. **German Language**: Most UI text, comments, and docstrings in German (core system docs in English)

## Deployment Notes

**Production Checklist** (see [docs/DEPLOYMENT.md](../docs/DEPLOYMENT.md)):
- FLASK_SECRET_KEY in `/etc/environment` (NOT in .env file)
- Run as systemd service with `gunicorn` WSGI server
- Nginx reverse proxy with HTTPS (set `BEHIND_REVERSE_PROXY=true`)
- Enable Flask-Talisman security headers (set `FORCE_HTTPS=true`)
- Fail2Ban integration for network-level IP banning

**Environment Variables** ([.env.example](../.env.example)):
- Required: `FLASK_SECRET_KEY`, `AI_BACKEND` (ollama/openai/anthropic/mistral)
- Optional: Provider API keys, Ollama base URL, web host/port
- Database: `DATABASE_PATH=emails.db` (SQLite, default location)

## When Making Changes

**Before editing:**
1. Check [docs/ZERO_KNOWLEDGE_COMPLETE.md](../docs/ZERO_KNOWLEDGE_COMPLETE.md) for encryption requirements
2. Search existing code for similar patterns (e.g., grep for existing routes/models)
3. Verify master_key handling - NEVER expose in logs, cookies, or client responses

**After editing:**
1. Run relevant tests: `pytest tests/test_<module>.py -v`
2. Check for security issues: No plaintext sensitive data in logs/responses
3. Update migrations if database schema changed
4. Test with both Ollama (local) and OpenAI (cloud) if AI-related

**Documentation:**
- Update [README.md](../README.md) for user-visible features
- Add technical details to [docs/](../docs/) if architectural changes
- Phase documentation in README tracks feature development history
