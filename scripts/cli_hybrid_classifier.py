#!/usr/bin/env python3
"""
CLI-Skripts f√ºr Hybrid Score-Learning System.

Kommandos:
1. python cli_hybrid_classifier.py trigger-training <user_id> <classifier_type> [--dry-run]
2. python cli_hybrid_classifier.py delete-user <user_id> [--dry-run]
3. python cli_hybrid_classifier.py cache-stats
4. python cli_hybrid_classifier.py train-check <user_id> <classifier_type>
5. python cli_hybrid_classifier.py cleanup-orphaned

Beispiele:
  # Training triggern
  python cli_hybrid_classifier.py trigger-training 1 dringlichkeit
  
  # Dry-Run
  python cli_hybrid_classifier.py delete-user 1 --dry-run
  
  # Cache-Statistiken
  python cli_hybrid_classifier.py cache-stats
"""

import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime, UTC
import shutil

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.helpers.database import get_session_factory
from src.services.personal_classifier_service import (
    get_classifier_dir,
    invalidate_classifier_cache,
    CLASSIFIER_TYPES,
    get_cache_stats,
)
from src.tasks.training_tasks import train_personal_classifier, THROTTLE_MIN_SAMPLES, THROTTLE_MIN_MINUTES

# ============================================================================
# Command 1: Trigger Training
# ============================================================================

def cmd_trigger_training(user_id: int, classifier_type: str, dry_run: bool = False):
    """Triggert Personal Classifier Training async."""
    
    print("\n" + "="*70)
    print(f"üéì TRAINING TRIGGER: user_id={user_id}, type={classifier_type}")
    print("="*70)
    
    if classifier_type not in CLASSIFIER_TYPES:
        print(f"‚ùå Ung√ºltiger classifier_type: {classifier_type}")
        print(f"   G√ºltige Typen: {CLASSIFIER_TYPES}")
        return 1
    
    SessionFactory = get_session_factory()
    db = SessionFactory()
    
    try:
        # 1. User pr√ºfen
        from importlib import import_module
        models = import_module(".02_models", "src")
        
        user = db.query(models.User).filter_by(id=user_id).first()
        if not user:
            print(f"‚ùå User {user_id} nicht gefunden")
            return 1
        
        print(f"‚úÖ User gefunden: {user.username}")
        
        # 2. Trainings-Daten z√§hlen
        override_field = {
            "dringlichkeit": "user_override_dringlichkeit",
            "wichtigkeit": "user_override_wichtigkeit",
            "spam": "user_override_spam_flag",
            "kategorie": "user_override_kategorie",
        }.get(classifier_type)
        
        if not override_field:
            print(f"‚ùå Unbekannter classifier_type: {classifier_type}")
            return 1
        
        correction_count = db.query(models.ProcessedEmail).filter(
            models.ProcessedEmail.user_id == user_id,
            getattr(models.ProcessedEmail, override_field) != None
        ).count()
        
        print(f"üìä Trainings-Samples vorhanden: {correction_count}")
        
        if correction_count < THROTTLE_MIN_SAMPLES:
            print(f"‚ö†Ô∏è  Throttling: Minimum {THROTTLE_MIN_SAMPLES} Samples erforderlich")
        
        # 3. Metadata pr√ºfen
        metadata = db.query(models.ClassifierMetadata).filter_by(
            user_id=user_id,
            classifier_type=classifier_type
        ).first()
        
        if metadata:
            print(f"üìà Letztes Training: {metadata.last_trained_at}")
            print(f"   Accuracy: {metadata.accuracy_score:.2%}" if metadata.accuracy_score else "")
            print(f"   Error Count: {metadata.error_count}")
            print(f"   Model Version: {metadata.model_version}")
            
            if metadata.error_count >= 3:
                print(f"üî¥ CIRCUIT-BREAKER AKTIV! Model ist deaktiviert.")
        else:
            print("üìù Noch nie trainiert (first_training)")
        
        # 4. Training triggern
        if dry_run:
            print("\nüîç DRY-RUN: W√ºrde Training triggern")
            print(f"   Task: train_personal_classifier.delay({user_id}, '{classifier_type}')")
        else:
            print(f"\n‚è≥ Training wird getriggert...")
            result = train_personal_classifier.delay(user_id, classifier_type)
            print(f"‚úÖ Task ID: {result.id}")
            print(f"   Status: Async eingereiht")
        
        return 0
    
    except Exception as e:
        print(f"‚ùå Fehler: {type(e).__name__}: {e}")
        return 1
    
    finally:
        db.close()


# ============================================================================
# Command 2: Delete User (mit Cleanup)
# ============================================================================

def cmd_delete_user(user_id: int, dry_run: bool = False):
    """L√∂scht User und seine Personal Classifier."""
    
    print("\n" + "="*70)
    print(f"üóëÔ∏è  USER DELETION: user_id={user_id}")
    print("="*70)
    
    SessionFactory = get_session_factory()
    db = SessionFactory()
    
    try:
        from importlib import import_module
        models = import_module(".02_models", "src")
        
        # 1. User pr√ºfen
        user = db.query(models.User).filter_by(id=user_id).first()
        if not user:
            print(f"‚ùå User {user_id} nicht gefunden")
            return 1
        
        print(f"‚úÖ User gefunden: {user.username}")
        
        # 2. Personal Classifiers pr√ºfen
        classifier_dir = get_classifier_dir()
        user_dir = classifier_dir / "per_user" / f"user_{user_id}"
        
        files_to_delete = []
        if user_dir.exists():
            files_to_delete = list(user_dir.glob("*.joblib")) + list(user_dir.glob("*.pkl"))
            print(f"üìÅ Personal Classifier Dateien gefunden: {len(files_to_delete)}")
            for f in files_to_delete:
                print(f"   - {f.name}")
        else:
            print(f"üìÅ Keine Personal Classifier Dateien")
        
        # 3. Metadata in DB pr√ºfen
        metadata_count = db.query(models.ClassifierMetadata).filter_by(
            user_id=user_id
        ).count()
        print(f"üìä Metadata-Eintr√§ge in DB: {metadata_count}")
        
        # 4. L√∂schung durchf√ºhren/simulieren
        if dry_run:
            print(f"\nüîç DRY-RUN: W√ºrde folgende Aktionen durchf√ºhren:")
            print(f"   1. Verzeichnis l√∂schen: {user_dir}")
            print(f"   2. Cache invalidieren: invalidate_classifier_cache(user_id={user_id})")
            print(f"   3. User aus DB l√∂schen: DELETE FROM users WHERE id={user_id}")
            print(f"   4. CASCADE: Alle FK-Referenzen l√∂schen")
        else:
            print(f"\n‚è≥ L√∂sche User und Classifier-Dateien...")
            
            # Dateien l√∂schen
            if user_dir.exists():
                shutil.rmtree(user_dir)
                print(f"‚úÖ Verzeichnis gel√∂scht: {user_dir}")
            
            # Cache invalidieren
            deleted_cache = invalidate_classifier_cache(user_id=user_id)
            print(f"‚úÖ Cache invalidiert: {deleted_cache} Eintr√§ge")
            
            # User l√∂schen (w√ºrde in echtem Kontext √ºber DELETE Endpoint gehen)
            print(f"‚ö†Ô∏è  User-L√∂schung aus DB: Manuell durchf√ºhren oder √ºber Admin-Panel")
            print(f"   SQL: DELETE FROM users WHERE id={user_id}")
        
        return 0
    
    except Exception as e:
        print(f"‚ùå Fehler: {type(e).__name__}: {e}")
        return 1
    
    finally:
        db.close()


# ============================================================================
# Command 3: Cache Statistics
# ============================================================================

def cmd_cache_stats():
    """Zeigt Cache-Statistiken."""
    
    print("\n" + "="*70)
    print("üíæ CACHE STATISTICS")
    print("="*70)
    
    try:
        stats = get_cache_stats()
        
        print(f"\nüìä Classifier Cache:")
        print(f"   Gr√∂√üe: {stats['classifier_cache_size']}/{stats['classifier_cache_maxsize']}")
        print(f"   TTL: {stats['classifier_cache_ttl']} Sekunden ({stats['classifier_cache_ttl']//60} Min)")
        
        print(f"\nüìä Scaler Cache:")
        print(f"   Gr√∂√üe: {stats['scaler_cache_size']}/{stats['scaler_cache_maxsize']}")
        print(f"   TTL: {stats['scaler_cache_ttl']} Sekunden ({stats['scaler_cache_ttl']//60} Min)")
        
        print(f"\nüîç Details:")
        print(f"   Total Cache Entries: {stats['classifier_cache_size'] + stats['scaler_cache_size']}")
        print(f"   Total Capacity: {stats['classifier_cache_maxsize'] + stats['scaler_cache_maxsize']}")
        
        return 0
    
    except Exception as e:
        print(f"‚ùå Fehler: {type(e).__name__}: {e}")
        return 1


# ============================================================================
# Command 4: Training Status Check
# ============================================================================

def cmd_train_check(user_id: int, classifier_type: str):
    """Pr√ºft ob Training f√ºr Classifier m√∂glich ist."""
    
    print("\n" + "="*70)
    print(f"üìã TRAINING CHECK: user_id={user_id}, type={classifier_type}")
    print("="*70)
    
    SessionFactory = get_session_factory()
    db = SessionFactory()
    
    try:
        from importlib import import_module
        models = import_module(".02_models", "src")
        from src.tasks.training_tasks import _should_trigger_training
        
        # 1. User pr√ºfen
        user = db.query(models.User).filter_by(id=user_id).first()
        if not user:
            print(f"‚ùå User {user_id} nicht gefunden")
            return 1
        
        print(f"‚úÖ User: {user.username}")
        print(f"   prefer_personal_classifier: {user.prefer_personal_classifier}")
        
        # 2. Throttling pr√ºfen
        should_train, reason = _should_trigger_training(user_id, classifier_type, db, models)
        
        print(f"\nüö¶ Throttling-Status:")
        if should_train:
            print(f"   ‚úÖ KANN TRAINIEREN: {reason}")
        else:
            print(f"   ‚ùå KANN NICHT TRAINIEREN: {reason}")
        
        # 3. Metadata Details
        metadata = db.query(models.ClassifierMetadata).filter_by(
            user_id=user_id,
            classifier_type=classifier_type
        ).first()
        
        if metadata:
            print(f"\nüìä Metadata:")
            print(f"   Samples: {metadata.training_samples}")
            print(f"   Accuracy: {metadata.accuracy_score:.2%}" if metadata.accuracy_score else "   Accuracy: -")
            print(f"   Error Count: {metadata.error_count}/3 (Circuit-Breaker)")
            print(f"   Version: {metadata.model_version}")
            print(f"   Last Trained: {metadata.last_trained_at}")
            print(f"   Active: {metadata.is_active}")
        else:
            print(f"\nüìä Metadata: Keine Eintr√§ge (noch nie trainiert)")
        
        # 4. Datei-Status
        classifier_dir = get_classifier_dir()
        personal_path = classifier_dir / "per_user" / f"user_{user_id}" / f"{classifier_type}.joblib"
        
        print(f"\nüìÅ Dateien:")
        print(f"   Personal: {'‚úÖ Existiert' if personal_path.exists() else '‚ùå Fehlt'}")
        
        return 0
    
    except Exception as e:
        print(f"‚ùå Fehler: {type(e).__name__}: {e}")
        return 1
    
    finally:
        db.close()


# ============================================================================
# Command 5: Cleanup Orphaned
# ============================================================================

def cmd_cleanup_orphaned():
    """L√∂scht orphaned Personal-Classifier-Dateien (ohne User in DB)."""
    
    print("\n" + "="*70)
    print("üßπ CLEANUP ORPHANED CLASSIFIERS")
    print("="*70)
    
    SessionFactory = get_session_factory()
    db = SessionFactory()
    
    try:
        from importlib import import_module
        models = import_module(".02_models", "src")
        
        classifier_dir = get_classifier_dir()
        per_user_dir = classifier_dir / "per_user"
        
        if not per_user_dir.exists():
            print("‚úÖ Keine Personal-Classifier vorhanden")
            return 0
        
        # Alle User-Verzeichnisse durchsuchen
        orphaned = []
        
        for user_dir in per_user_dir.iterdir():
            if not user_dir.is_dir():
                continue
            
            # Extrahiere user_id aus "user_X"
            try:
                user_id = int(user_dir.name.split("_")[1])
            except (ValueError, IndexError):
                continue
            
            # Pr√ºfe ob User existiert
            user = db.query(models.User).filter_by(id=user_id).first()
            if not user:
                orphaned.append(user_dir)
                print(f"‚ùå Orphaned: {user_dir.name} (user_id={user_id} nicht in DB)")
        
        if not orphaned:
            print("‚úÖ Keine orphaned Classifiers gefunden")
            return 0
        
        # L√∂schen
        print(f"\n‚è≥ L√∂sche {len(orphaned)} orphaned Verzeichnisse...")
        for user_dir in orphaned:
            try:
                shutil.rmtree(user_dir)
                print(f"‚úÖ Gel√∂scht: {user_dir.name}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Fehler beim L√∂schen {user_dir.name}: {e}")
        
        return 0
    
    except Exception as e:
        print(f"‚ùå Fehler: {type(e).__name__}: {e}")
        return 1
    
    finally:
        db.close()


# ============================================================================
# MAIN
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="CLI f√ºr Hybrid Score-Learning System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Kommando')
    
    # Trigger Training
    p1 = subparsers.add_parser('trigger-training', help='Triggert Personal Classifier Training')
    p1.add_argument('user_id', type=int, help='User ID')
    p1.add_argument('classifier_type', choices=CLASSIFIER_TYPES, help='Classifier-Typ')
    p1.add_argument('--dry-run', action='store_true', help='Nur anzeigen, nicht ausf√ºhren')
    
    # Delete User
    p2 = subparsers.add_parser('delete-user', help='L√∂scht User + Personal Classifiers')
    p2.add_argument('user_id', type=int, help='User ID')
    p2.add_argument('--dry-run', action='store_true', help='Nur anzeigen, nicht ausf√ºhren')
    
    # Cache Stats
    p3 = subparsers.add_parser('cache-stats', help='Zeigt Cache-Statistiken')
    
    # Training Check
    p4 = subparsers.add_parser('train-check', help='Pr√ºft Trainings-Status')
    p4.add_argument('user_id', type=int, help='User ID')
    p4.add_argument('classifier_type', choices=CLASSIFIER_TYPES, help='Classifier-Typ')
    
    # Cleanup Orphaned
    p5 = subparsers.add_parser('cleanup-orphaned', help='L√∂scht orphaned Classifiers')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return 1
    
    # Execute commands
    if args.command == 'trigger-training':
        return cmd_trigger_training(args.user_id, args.classifier_type, args.dry_run)
    elif args.command == 'delete-user':
        return cmd_delete_user(args.user_id, args.dry_run)
    elif args.command == 'cache-stats':
        return cmd_cache_stats()
    elif args.command == 'train-check':
        return cmd_train_check(args.user_id, args.classifier_type)
    elif args.command == 'cleanup-orphaned':
        return cmd_cleanup_orphaned()
    
    return 0


if __name__ == '__main__':
    sys.exit(main())
